{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the text report in a format suitable for input to the OpenAlex concept tagging model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Specify the input folder containing the text files and the output folder for the JSON files\n",
    "input_folder_path = \".\\i2b2_2010_VA_training_data\\consolidated_text_reports_training_data\"\n",
    "output_folder_path = \".\\i2b2_2010_VA_training_data\\i2b2_text_reports_OpenAlex_processing\"\n",
    "\n",
    "# Ensure the output folder exists, create if it doesn't\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Loop through each file in the input folder\n",
    "for filename in os.listdir(input_folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(input_folder_path, filename)\n",
    "        \n",
    "        # Read the content of the text file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            abstract_text = file.read()\n",
    "        \n",
    "        # Create a JSON object\n",
    "        json_data = [{\n",
    "            \"title\": None,\n",
    "            \"doc_type\": None,\n",
    "            \"journal\": None,\n",
    "            \"abstract\": abstract_text,\n",
    "            \"inverted_abstract\": False,\n",
    "            \"paper_id\": None\n",
    "        }]\n",
    "        \n",
    "        # Construct the output file name and path (.txt replaced with .json)\n",
    "        output_file_name = os.path.splitext(filename)[0] + '.json'\n",
    "        output_file_path = os.path.join(output_folder_path, output_file_name)\n",
    "        \n",
    "        # Save the JSON object to a file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(json_data, json_file, indent=2, ensure_ascii=False)\n",
    "print(\"Conversion completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model and predict concepts for each text report.\n",
    "\n",
    "Run the flask server.\n",
    "Install Flask and Dependencies --> pip install Flask tensorflow pandas numpy\n",
    "Set Flask Environment Variables (windows cmd) --> set FLASK_APP=app.py\n",
    "                                    set FLASK_ENV=development\n",
    "Run the Flask Application --> flask run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for 018636330_DH.json saved successfully.\n",
      "Response for 026350193_RWH.json saved successfully.\n",
      "Response for 037945397_RWH.json saved successfully.\n",
      "Response for 044687343_ELMVH.json saved successfully.\n",
      "Response for 060376519_DH.json saved successfully.\n",
      "Response for 095889687_WGH.json saved successfully.\n",
      "Response for 101407944_PUMC.json saved successfully.\n",
      "Response for 105732749.json saved successfully.\n",
      "Response for 115026438_SC.json saved successfully.\n",
      "Response for 130959255.json saved successfully.\n",
      "Response for 134300717.json saved successfully.\n",
      "Response for 143748600_SC.json saved successfully.\n",
      "Response for 145980160.json saved successfully.\n",
      "Response for 156406283.json saved successfully.\n",
      "Response for 176318078_a.json saved successfully.\n",
      "Response for 176746010_WGH.json saved successfully.\n",
      "Response for 188543380.json saved successfully.\n",
      "Response for 194442600_RWH.json saved successfully.\n",
      "Response for 212512774_WGH.json saved successfully.\n",
      "Response for 223159990.json saved successfully.\n",
      "Response for 245096078.json saved successfully.\n",
      "Response for 245317863_WGH.json saved successfully.\n",
      "Response for 262182942.json saved successfully.\n",
      "Response for 262912613.json saved successfully.\n",
      "Response for 270045381.json saved successfully.\n",
      "Response for 274230067_EH.json saved successfully.\n",
      "Response for 284487129.json saved successfully.\n",
      "Response for 289811204.json saved successfully.\n",
      "Response for 297228405_DH.json saved successfully.\n",
      "Response for 306968218_YC.json saved successfully.\n",
      "Response for 320422564.json saved successfully.\n",
      "Response for 332803550.json saved successfully.\n",
      "Response for 333521954.json saved successfully.\n",
      "Response for 337702516_WGH.json saved successfully.\n",
      "Response for 346176858_SC.json saved successfully.\n",
      "Response for 348301810.json saved successfully.\n",
      "Response for 351853846_WGH.json saved successfully.\n",
      "Response for 373254497_PUMC.json saved successfully.\n",
      "Response for 384729825.json saved successfully.\n",
      "Response for 388755206_SC.json saved successfully.\n",
      "Response for 402389409_WGH.json saved successfully.\n",
      "Response for 405507617.json saved successfully.\n",
      "Response for 405868244_YC.json saved successfully.\n",
      "Response for 412141256.json saved successfully.\n",
      "Response for 424729395_DH.json saved successfully.\n",
      "Response for 425680098_SC.json saved successfully.\n",
      "Response for 433651389.json saved successfully.\n",
      "Response for 455343475_PUMC.json saved successfully.\n",
      "Response for 493597270.json saved successfully.\n",
      "Response for 498710998.json saved successfully.\n",
      "Response for 500472963.json saved successfully.\n",
      "Response for 503651854_WGH.json saved successfully.\n",
      "Response for 517414339.json saved successfully.\n",
      "Response for 523704694.json saved successfully.\n",
      "Response for 544907529_RWH.json saved successfully.\n",
      "Response for 555509347_PUMC.json saved successfully.\n",
      "Response for 574700124_RWH.json saved successfully.\n",
      "Response for 596437842.json saved successfully.\n",
      "Response for 598403789_DH.json saved successfully.\n",
      "Response for 614746156.json saved successfully.\n",
      "Response for 622086964.json saved successfully.\n",
      "Response for 627258104.json saved successfully.\n",
      "Response for 638157550_SC.json saved successfully.\n",
      "Response for 641557794_WGH.json saved successfully.\n",
      "Response for 655358166_WGH.json saved successfully.\n",
      "Response for 688127038_EH.json saved successfully.\n",
      "Response for 693008750.json saved successfully.\n",
      "Response for 699905656_SC.json saved successfully.\n",
      "Response for 708739405_DH.json saved successfully.\n",
      "Response for 723989226.json saved successfully.\n",
      "Response for 745431641_WGH.json saved successfully.\n",
      "Response for 745701560_WGH.json saved successfully.\n",
      "Response for 767751445_ELMVH.json saved successfully.\n",
      "Response for 779878634.json saved successfully.\n",
      "Response for 788268693_DH.json saved successfully.\n",
      "Response for 814743340_RWH.json saved successfully.\n",
      "Response for 817406016_RWH.json saved successfully.\n",
      "Response for 825330116.json saved successfully.\n",
      "Response for 837898389.json saved successfully.\n",
      "Response for 839999049_YC.json saved successfully.\n",
      "Response for 843566350_RWH.json saved successfully.\n",
      "Response for 853262744.json saved successfully.\n",
      "Response for 869436718_SC.json saved successfully.\n",
      "Response for 879492218_YC.json saved successfully.\n",
      "Response for 888428725_RWH.json saved successfully.\n",
      "Response for 891864133_RWH.json saved successfully.\n",
      "Response for 910458031.json saved successfully.\n",
      "Response for 915093496_RWH.json saved successfully.\n",
      "Response for 917989835_RWH.json saved successfully.\n",
      "Response for 920798564.json saved successfully.\n",
      "Response for 932057504_DH.json saved successfully.\n",
      "Response for 950452368.json saved successfully.\n",
      "Response for 959086752.json saved successfully.\n",
      "Response for 965367286_WGH.json saved successfully.\n",
      "Response for 974381789.json saved successfully.\n",
      "Response for 979440029_RWH.json saved successfully.\n",
      "Response for 989519730_WGH.json saved successfully.\n",
      "Response for record-105.json saved successfully.\n",
      "Response for record-106.json saved successfully.\n",
      "Response for record-107.json saved successfully.\n",
      "Response for record-108.json saved successfully.\n",
      "Response for record-109.json saved successfully.\n",
      "Response for record-121.json saved successfully.\n",
      "Response for record-122.json saved successfully.\n",
      "Response for record-123.json saved successfully.\n",
      "Response for record-124.json saved successfully.\n",
      "Response for record-13.json saved successfully.\n",
      "Response for record-14.json saved successfully.\n",
      "Response for record-140.json saved successfully.\n",
      "Response for record-141.json saved successfully.\n",
      "Response for record-142.json saved successfully.\n",
      "Response for record-143.json saved successfully.\n",
      "Response for record-144.json saved successfully.\n",
      "Response for record-15.json saved successfully.\n",
      "Response for record-16.json saved successfully.\n",
      "Response for record-17.json saved successfully.\n",
      "Response for record-175.json saved successfully.\n",
      "Response for record-176.json saved successfully.\n",
      "Response for record-177.json saved successfully.\n",
      "Response for record-178.json saved successfully.\n",
      "Response for record-179.json saved successfully.\n",
      "Response for record-18.json saved successfully.\n",
      "Response for record-19.json saved successfully.\n",
      "Response for record-20.json saved successfully.\n",
      "Response for record-21.json saved successfully.\n",
      "Response for record-22.json saved successfully.\n",
      "Response for record-23.json saved successfully.\n",
      "Response for record-24.json saved successfully.\n",
      "Response for record-25.json saved successfully.\n",
      "Response for record-26.json saved successfully.\n",
      "Response for record-27.json saved successfully.\n",
      "Response for record-28.json saved successfully.\n",
      "Response for record-29.json saved successfully.\n",
      "Response for record-30.json saved successfully.\n",
      "Response for record-31.json saved successfully.\n",
      "Response for record-32.json saved successfully.\n",
      "Response for record-33.json saved successfully.\n",
      "Response for record-34.json saved successfully.\n",
      "Response for record-35.json saved successfully.\n",
      "Response for record-36.json saved successfully.\n",
      "Response for record-37.json saved successfully.\n",
      "Response for record-38.json saved successfully.\n",
      "Response for record-45.json saved successfully.\n",
      "Response for record-46.json saved successfully.\n",
      "Response for record-47.json saved successfully.\n",
      "Response for record-48.json saved successfully.\n",
      "Response for record-49.json saved successfully.\n",
      "Response for record-50.json saved successfully.\n",
      "Response for record-51.json saved successfully.\n",
      "Response for record-52.json saved successfully.\n",
      "Response for record-53.json saved successfully.\n",
      "Response for record-54.json saved successfully.\n",
      "Response for record-55.json saved successfully.\n",
      "Response for record-56.json saved successfully.\n",
      "Response for record-58.json saved successfully.\n",
      "Response for record-59.json saved successfully.\n",
      "Response for record-65.json saved successfully.\n",
      "Response for record-66.json saved successfully.\n",
      "Response for record-67.json saved successfully.\n",
      "Response for record-68.json saved successfully.\n",
      "Response for record-69.json saved successfully.\n",
      "Response for record-70.json saved successfully.\n",
      "Response for record-71.json saved successfully.\n",
      "Response for record-73.json saved successfully.\n",
      "Response for record-74.json saved successfully.\n",
      "Response for record-80.json saved successfully.\n",
      "Response for record-81.json saved successfully.\n",
      "Response for record-82.json saved successfully.\n",
      "Response for record-83.json saved successfully.\n",
      "Response for record-84.json saved successfully.\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Specify the folder containing the JSON files and where to save the responses\n",
    "json_folder_path = \".\\i2b2_2010_VA_training_data\\i2b2_text_reports_OpenAlex_processing\"\n",
    "response_folder_path = \".\\i2b2_2010_VA_training_data\\i2b2_text_reports_OpenAlex_processing\\OpenAlex_output\"\n",
    "\n",
    "# Ensure the response folder exists, create if it doesn't\n",
    "os.makedirs(response_folder_path, exist_ok=True)\n",
    "\n",
    "# The URL of your Flask application's /invocations endpoint\n",
    "url = 'http://127.0.0.1:5000/invocations'\n",
    "\n",
    "# Loop through each JSON file in the folder\n",
    "for filename in os.listdir(json_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        json_file_path = os.path.join(json_folder_path, filename)\n",
    "        \n",
    "        # Read the JSON file content\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "            json_data = json_file.read()\n",
    "        \n",
    "        # Send the POST request with JSON data\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        response = requests.post(url, data=json_data, headers=headers)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Construct the response file name (.json replaced with _response.json)\n",
    "            response_file_name = os.path.splitext(filename)[0] + '.json'\n",
    "            response_file_path = os.path.join(response_folder_path, response_file_name)\n",
    "            \n",
    "            # Save the response content to a new file\n",
    "            with open(response_file_path, 'w', encoding='utf-8') as response_file:\n",
    "                response_file.write(response.text)\n",
    "            print(f\"Response for {filename} saved successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to get a response for {filename}. Status code: {response.status_code}\")\n",
    "print(\"All done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "information parsing from OpenAlex model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Concepts</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>018636330_DH.json</td>\n",
       "      <td>[medicine, clonus, hyperreflexia, physical exa...</td>\n",
       "      <td>[0.9112345576286316, 0.7156546115875244, 0.610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>026350193_RWH.json</td>\n",
       "      <td>[medicine, nausea, constipation, codeine, vomi...</td>\n",
       "      <td>[0.7432302832603455, 0.5929043889045715, 0.591...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>037945397_RWH.json</td>\n",
       "      <td>[medicine, chest pain, weakness, syncope, pedi...</td>\n",
       "      <td>[0.8295673727989197, 0.5714144706726074, 0.482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>044687343_ELMVH.json</td>\n",
       "      <td>[fluticasone propionate, chemistry, medicine, ...</td>\n",
       "      <td>[0.6071492433547974, 0.49507227540016174, 0.42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>060376519_DH.json</td>\n",
       "      <td>[medicine, complaint, emergency department, la...</td>\n",
       "      <td>[0.7121383547782898, 0.5547797679901123, 0.483...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Name                                           Concepts  \\\n",
       "0     018636330_DH.json  [medicine, clonus, hyperreflexia, physical exa...   \n",
       "1    026350193_RWH.json  [medicine, nausea, constipation, codeine, vomi...   \n",
       "2    037945397_RWH.json  [medicine, chest pain, weakness, syncope, pedi...   \n",
       "3  044687343_ELMVH.json  [fluticasone propionate, chemistry, medicine, ...   \n",
       "4     060376519_DH.json  [medicine, complaint, emergency department, la...   \n",
       "\n",
       "                                              Scores  \n",
       "0  [0.9112345576286316, 0.7156546115875244, 0.610...  \n",
       "1  [0.7432302832603455, 0.5929043889045715, 0.591...  \n",
       "2  [0.8295673727989197, 0.5714144706726074, 0.482...  \n",
       "3  [0.6071492433547974, 0.49507227540016174, 0.42...  \n",
       "4  [0.7121383547782898, 0.5547797679901123, 0.483...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Assuming the folder path is 'data/json_files', replace it with the actual path of your JSON files\n",
    "folder_path = \".\\i2b2_2010_VA_training_data\\i2b2_text_reports_OpenAlex_processing\\OpenAlex_output\"\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each file in the specified folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a JSON file\n",
    "    if file_name.endswith('.json'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # Open and load the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = json.load(file)\n",
    "            # Initialize empty lists to store tags and scores\n",
    "            tags = []\n",
    "            scores = []\n",
    "            # Iterate through each item in the JSON data\n",
    "            for item in content:\n",
    "                # Filter tags and scores based on the score condition (> 0.3)\n",
    "                filtered_tags_scores = [(tag, score) for tag, score in zip(item['tags'], item['scores']) if score > 0.3]\n",
    "                # Unpack the filtered tags and scores\n",
    "                if filtered_tags_scores:\n",
    "                    tags, scores = zip(*filtered_tags_scores)\n",
    "                else:\n",
    "                    tags, scores = (), ()\n",
    "            # Append the file name, tags, and scores to the data list\n",
    "            data.append([file_name, list(tags), list(scores)])\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data, columns=['File Name', 'Concepts', 'Scores'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map concepts with UMLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from cachetools import cached, TTLCache\n",
    "\n",
    "# Define a cache with a TTL (time-to-live) of 24 hours for search results\n",
    "cache = TTLCache(maxsize=100, ttl=86400)\n",
    "\n",
    "@cached(cache)\n",
    "def search_umls(term, api_key, base_url='https://uts-ws.nlm.nih.gov/rest/search/current', pageSize=25):\n",
    "    all_cuis = []\n",
    "    pageNumber = 1\n",
    "    totalResults = float('inf')  # Set to infinity initially to enter the loop\n",
    "\n",
    "    while len(all_cuis) < totalResults:\n",
    "        try:\n",
    "            response = requests.get(f'{base_url}?string={term}&apiKey={api_key}&searchType=exact&pageSize={pageSize}&pageNumber={pageNumber}')\n",
    "            data = response.json()\n",
    "            results = data['result']['results']\n",
    "            totalResults = data['result']['recCount']  # Total number of results for the term\n",
    "\n",
    "            all_cuis.extend([result['ui'] for result in results])\n",
    "\n",
    "            pageNumber += 1  # Increment page number for next iteration\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing term '{term}': {e}\")\n",
    "            break  # Exit loop in case of an error\n",
    "\n",
    "    return all_cuis\n",
    "\n",
    "@cached(cache)\n",
    "def get_tuis_for_cui(cui, api_key, base_url='https://uts-ws.nlm.nih.gov/rest/content', version='2023AB'):\n",
    "    try:\n",
    "        response = requests.get(f'{base_url}/{version}/CUI/{cui}?apiKey={api_key}')\n",
    "        data = response.json()\n",
    "        semantic_types = data['result']['semanticTypes']\n",
    "        return [semantic_type['uri'].split('/')[-1] for semantic_type in semantic_types if semantic_type.get('uri')]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CUI '{cui}': {e}\")\n",
    "        return []\n",
    "\n",
    "def retrieve_cuis_and_tuis_from_umls(word_list, api_key, version='2023AB', request_delay=0.1):\n",
    "    cuis = set()\n",
    "    tuis = set()\n",
    "\n",
    "    for term in word_list:\n",
    "        term_cuis = search_umls(term, api_key)\n",
    "        cuis.update(term_cuis)\n",
    "        time.sleep(request_delay)\n",
    "\n",
    "    for cui in cuis:\n",
    "        cui_tuis = get_tuis_for_cui(cui, api_key, version=version)\n",
    "        tuis.update(cui_tuis)\n",
    "        time.sleep(request_delay)\n",
    "\n",
    "    return list(cuis), list(tuis)\n",
    "\n",
    "# Your UMLS API key\n",
    "api_key = 'efd9c726-5226-43c1-8cb1-c5ac40bae98c'\n",
    "\n",
    "# Function to map tags to CUIs and TUIs for each row in the dataframe\n",
    "def map_tags_to_cuis_and_tuis(tags, api_key):\n",
    "    cuis, tuis = retrieve_cuis_and_tuis_from_umls(tags, api_key)\n",
    "    return cuis, tuis\n",
    "\n",
    "# Applying the mapping function to each row in the dataframe and storing the result in new columns\n",
    "df[['CUIs', 'TUIs']] = df['Concepts'].apply(lambda tags: pd.Series(map_tags_to_cuis_and_tuis(tags, api_key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Concepts</th>\n",
       "      <th>Scores</th>\n",
       "      <th>CUIs</th>\n",
       "      <th>TUIs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>018636330_DH.json</td>\n",
       "      <td>[medicine, clonus, hyperreflexia, physical exa...</td>\n",
       "      <td>[0.9112345576286316, 0.7156546115875244, 0.610...</td>\n",
       "      <td>[C0013227, C0220870, C0038895, C0262926, C0025...</td>\n",
       "      <td>[T169, T184, T058, T060, T091, T033, T078, T12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>026350193_RWH.json</td>\n",
       "      <td>[medicine, nausea, constipation, codeine, vomi...</td>\n",
       "      <td>[0.7432302832603455, 0.5929043889045715, 0.591...</td>\n",
       "      <td>[C0013227, C0002912, C0699718, C3864418, C0949...</td>\n",
       "      <td>[T201, T184, T091, T033, T170, T121, T061, T109]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>037945397_RWH.json</td>\n",
       "      <td>[medicine, chest pain, weakness, syncope, pedi...</td>\n",
       "      <td>[0.8295673727989197, 0.5714144706726074, 0.482...</td>\n",
       "      <td>[C3714552, C0013227, C0587599, C0002912, C0030...</td>\n",
       "      <td>[T201, T011, T184, T058, T091, T033, T121, T061]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>044687343_ELMVH.json</td>\n",
       "      <td>[fluticasone propionate, chemistry, medicine, ...</td>\n",
       "      <td>[0.6071492433547974, 0.49507227540016174, 0.42...</td>\n",
       "      <td>[C0013227, C0002912, C0025118, C2219802, C0117...</td>\n",
       "      <td>[T059, T169, T201, T090, T184, T033, T091, T17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>060376519_DH.json</td>\n",
       "      <td>[medicine, complaint, emergency department, la...</td>\n",
       "      <td>[0.7121383547782898, 0.5547797679901123, 0.483...</td>\n",
       "      <td>[C0013227, C0587599, C0022893, C1069915, C3864...</td>\n",
       "      <td>[T093, T204, T201, T184, T058, T047, T091, T03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Name                                           Concepts  \\\n",
       "0     018636330_DH.json  [medicine, clonus, hyperreflexia, physical exa...   \n",
       "1    026350193_RWH.json  [medicine, nausea, constipation, codeine, vomi...   \n",
       "2    037945397_RWH.json  [medicine, chest pain, weakness, syncope, pedi...   \n",
       "3  044687343_ELMVH.json  [fluticasone propionate, chemistry, medicine, ...   \n",
       "4     060376519_DH.json  [medicine, complaint, emergency department, la...   \n",
       "\n",
       "                                              Scores  \\\n",
       "0  [0.9112345576286316, 0.7156546115875244, 0.610...   \n",
       "1  [0.7432302832603455, 0.5929043889045715, 0.591...   \n",
       "2  [0.8295673727989197, 0.5714144706726074, 0.482...   \n",
       "3  [0.6071492433547974, 0.49507227540016174, 0.42...   \n",
       "4  [0.7121383547782898, 0.5547797679901123, 0.483...   \n",
       "\n",
       "                                                CUIs  \\\n",
       "0  [C0013227, C0220870, C0038895, C0262926, C0025...   \n",
       "1  [C0013227, C0002912, C0699718, C3864418, C0949...   \n",
       "2  [C3714552, C0013227, C0587599, C0002912, C0030...   \n",
       "3  [C0013227, C0002912, C0025118, C2219802, C0117...   \n",
       "4  [C0013227, C0587599, C0022893, C1069915, C3864...   \n",
       "\n",
       "                                                TUIs  \n",
       "0  [T169, T184, T058, T060, T091, T033, T078, T12...  \n",
       "1   [T201, T184, T091, T033, T170, T121, T061, T109]  \n",
       "2   [T201, T011, T184, T058, T091, T033, T121, T061]  \n",
       "3  [T059, T169, T201, T090, T184, T033, T091, T17...  \n",
       "4  [T093, T204, T201, T184, T058, T047, T091, T03...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('.\\i2b2_2010_VA_training_data\\i2b2_text_reports_OpenAlex_processing\\OpenAlex_output\\i2b2_text_parsed_concepts_OA.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
